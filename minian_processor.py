# D:\Desktop\ZJU\SRTP\ui_v1\minian_processor.py

import numpy as np
import xarray as xr
import pandas as pd
from typing import Dict, Any, Tuple, Optional, Union
import json
import os
import dask.array as da
import dask.dataframe as dd
import matplotlib.pyplot as plt
import cv2
import traceback

# ====================================================================
# ä¿®æ­£åçš„å¯¼å…¥å—ï¼šä¸¥æ ¼æ ¹æ®æ‚¨æä¾›çš„å‡½æ•°åˆ—è¡¨å’Œé”™è¯¯è·¯å¾„ (minian_core)
# ====================================================================

from minian_core.cnmf import ( 
    compute_AtC,
    compute_trace,
    get_noise_fft,
    smooth_sig,
    unit_merge,
    update_spatial, # âœ… CNMF ç©ºé—´æ›´æ–°
    update_temporal, # âœ… CNMF æ—¶é—´æ›´æ–°
    update_background,
)
from minian_core.initialization import (
    gmm_refine,
    initA,       # âœ… ç©ºé—´åˆå§‹åŒ–å‡½æ•°
    initC,       # âœ… æ—¶é—´åˆå§‹åŒ–å‡½æ•°
    intensity_refine,
    ks_refine,
    pnr_refine,
    seeds_init,
    seeds_merge, # âœ… ä¿®æ­£ï¼šç”¨äºåˆå¹¶ç§å­ç‚¹çš„æ­£ç¡®å‡½æ•°å
)
from minian_core.motion_correction import apply_transform, estimate_motion,apply_shifts
from minian_core.preprocessing import denoise, remove_background,remove_glow
from minian_core.utilities import (
    TaskAnnotation,
    get_optimal_chk,
    load_videos,
    open_minian,
    save_minian,
    # ... å…¶ä»– utilities å‡½æ•°
)
from minian_core.visualization import (
    create_cnmf_update_plot, 
    create_spatial_update_plot, 
    create_temporal_matrix_plot, 
    create_merge_matrix_plot
    
)


class MinianProcessor:
    """
    Minian å¤„ç†æµç¨‹çš„å°è£…ç±»ã€‚
    è¯·å°†ä»¥ä¸‹æ–¹æ³•æ›¿æ¢/è¡¥å……åˆ°æ‚¨ç°æœ‰ç±»ä¸­ï¼Œä»¥ç¡®ä¿å‡½æ•°è°ƒç”¨æ­£ç¡®ã€‚
    """
    
    def __init__(self, video_folder: str, config_path: str, repo_dir: str = None):
        self.video_folder = video_folder 
        self.config_path = config_path 
        self.dpath = video_folder 
        
        self.repo_dir = repo_dir or os.path.dirname(os.path.abspath(__file__))
        self.fps = 20.0
        self.log_output = [] 
        self.step_statuses = {}
        self.steps_results = {}
        
        self.data_path = os.path.join(self.dpath, "minian_visual_cache")
        
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f) 
            # å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ æ—¥å¿—æˆ–æ‰“å°ä¿¡æ¯
            print(f"é…ç½®æ–‡ä»¶ä» {config_path} åŠ è½½æˆåŠŸã€‚")
        except FileNotFoundError:
            print(f"é”™è¯¯: é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°äº {config_path}")
            self.config = {}
        except json.JSONDecodeError:
            print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ {config_path} æ ¼å¼é”™è¯¯ (éæœ‰æ•ˆ JSON)ã€‚")
            self.config = {}
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‘ç”Ÿå…¶ä»–é”™è¯¯: {e}")
            self.config = {}
        
        # ğŸ”´ å…³é”®ä¿®æ­£ 4ï¼šåˆå§‹åŒ–æ•°æ®ä»“åº“
        self.data_repo = {} 
        
    def get_step_params(self, step_name: str) -> Dict[str, Any]:
        # æ‚¨çš„è·å–å‚æ•°æ–¹æ³•ä»£ç ...
        return self.config.get(step_name, {})

    def _load_data_from_repo(self, key: str) -> Any:
        """ä»ä»“åº“åŠ è½½æ•°æ®"""
        return self.data_repo.get(key)
        
    def _save_data_to_repo(self, data: Any, key: str) -> Any:
        """ä¿å­˜æ•°æ®åˆ°ä»“åº“"""
        self.data_repo[key] = data
        return data
        
    def _update_config_param(self, param_name, value):
        """
        æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°
        """
        if hasattr(self, 'config'):
            self.config[param_name] = value
            # ä¿å­˜æ›´æ–°åçš„é…ç½®
            with open(self.config_path, 'w') as f:
                json.dump(self.config, f, indent=4)
                    
    def get_video_fps(self):
        """UI è°ƒç”¨æ­¤æ–¹æ³•è·å–å½“å‰è§†é¢‘çš„å¸§ç‡ã€‚"""
        return self.fps
    
    def _save_config(self):
        """ç§æœ‰æ–¹æ³•ï¼šå°†å†…å­˜ä¸­çš„é…ç½®å†™å…¥ config.json æ–‡ä»¶ã€‚"""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            # æœ€å¥½åœ¨å®é™…é¡¹ç›®ä¸­åŠ ä¸Šé”™è¯¯å¤„ç†
            print(f"é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
    def update_params(self, step_name: str, new_params: dict):
        """
        æ¥æ”¶ä¸€ä¸ªæ­¥éª¤çš„æ‰€æœ‰ä¿®æ”¹å‚æ•°ï¼Œåˆå¹¶åˆ°å†…å­˜é…ç½®ï¼Œå¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚
        """
        if step_name not in self.config:
            print(f"è­¦å‘Š: é…ç½®ä¸­æœªæ‰¾åˆ°æ­¥éª¤ {step_name}")
            return

        # ä½¿ç”¨å­—å…¸çš„ update() æ–¹æ³•ï¼Œå°† new_params ä¸­çš„é”®å€¼å¯¹åˆå¹¶åˆ°ç°æœ‰é…ç½®ä¸­
        self.config[step_name].update(new_params)
        
        # ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶
        self._save_config()
        
    def update_config_param(self, step_name: str, key: str, value: Any):
        """
        ç”¨äº UI æ¨¡å¼åˆ‡æ¢ï¼Œæ›´æ–°å•ä¸ªé…ç½®å‚æ•°å¹¶ç«‹å³ä¿å­˜ã€‚
        """
        if step_name not in self.config:
            return

        # 1. æ›´æ–°å†…å­˜ä¸­çš„é…ç½®
        self.config[step_name][key] = value

        # 2. å†™å…¥æ–‡ä»¶ï¼Œç¡®ä¿ä¿®æ”¹ç”Ÿæ•ˆ
        self._save_config() 
                
    def update_step_status(self, step_name: str, status: str):
        """
        æ›´æ–°ç‰¹å®šæ­¥éª¤çš„è¿è¡ŒçŠ¶æ€ã€‚
        ï¼ˆè¿™ä¸ªæ–¹æ³•æ˜¯æ‚¨ä»£ç è¿è¡Œé€»è¾‘æ‰€ä¾èµ–çš„ï¼‰
        """
        # å‡è®¾è¿™é‡Œæ˜¯æ›´æ–°çŠ¶æ€å­—å…¸æˆ– UI ç•Œé¢çš„é€»è¾‘
        if hasattr(self, 'status_log'):
            self.status_log[step_name] = status
        # æˆ–è€…å…¶ä»–å…·ä½“çš„å®ç°ï¼Œä¾‹å¦‚æ‰“å°åˆ°æ—¥å¿—
        print(f"[STATUS] {step_name}: {status}")
        
    def get_varr_for_vis(self, step_name: str) -> Optional[xr.DataArray]:
        """
        æ ¹æ®æ­¥éª¤åç§°ï¼Œä»æ•°æ®ä»“åº“ä¸­æ£€ç´¢ç”¨äºå¯è§†åŒ–çš„ xarray.DataArray (varr)ã€‚
        å¯¹äºä¸éœ€è¦è§†é¢‘æ•°ç»„ä½œä¸ºèƒŒæ™¯çš„æ­¥éª¤ï¼Œè¿”å› Noneã€‚
        """
        
        # æ­¥éª¤ååˆ°æ•°æ®ä»“åº“é”®çš„æ˜ å°„
        # é”®ååŸºäº Minian çš„æ ‡å‡†ä¸­é—´ç»“æœå‘½åæƒ¯ä¾‹
        data_key_map = {
            # è§†é¢‘é¢„å¤„ç†æ­¥éª¤ (è¿”å›å½“å‰æ­¥éª¤çš„ç»“æœ)
            'load_video_1': 'varr_glow',      # æ­¥éª¤1ï¼šåŠ è½½è§†é¢‘/å»å…‰æ™•åçš„ç»“æœ
            'background_removal': 'varr_final_processed', # æ­¥éª¤2ï¼šå»é™¤èƒŒæ™¯åçš„ç»“æœ
            'denoise': 'varr_temporally_detrended',                # æ­¥éª¤3ï¼šé™å™ªåçš„ç»“æœ
            'motion_correction': 'varr_mc',  # æ­¥éª¤4ï¼šè¿åŠ¨æ ¡æ­£åçš„ç»“æœ (æœ€å¹²å‡€çš„èƒŒæ™¯)
            
            # ç§å­ç‚¹/åˆå§‹åŒ–æ­¥éª¤ (ä»¥æœ€å¹²å‡€çš„è§†é¢‘ä½œä¸ºå¯è§†åŒ–èƒŒæ™¯)
            'seeds_init': 'video_for_seeds_vis',
            'ks_refine': 'video_for_seeds_vis',
            'merge_seeds': 'video_for_seeds_vis',
            'visualization_init': 'video_for_seeds_vis',
            
            # éè§†é¢‘/å›¾åƒå¯è§†åŒ–æ­¥éª¤ (è¿”å› Noneï¼Œè®© UI æ ¹æ® steps_results å¤„ç†)
            'peak_noise_ratio_refine': None,      # æ›²çº¿ (curve)
            'first_spatial_update_explore': None, # æ¢ç´¢ (exploration)
            'first_spatial_update_exec': None,    # CNMFæ›´æ–° (cnmf_update)
            'first_temporal_update_explore': None,
            'first_temporal_update_exec': None,
            'second_spatial_update': None,
            'second_temporal_update': None,
            'save_data': None,                    # æ— å¯è§†åŒ– (none)
        }
        
        data_key = data_key_map.get(step_name)
        
        if data_key is None:
            # å¯¹äºä¸éœ€è¦è§†é¢‘æ•°ç»„çš„æ­¥éª¤ï¼Œç›´æ¥è¿”å› None
            return None
            
        # ä½¿ç”¨å·²æœ‰çš„æ•°æ®åŠ è½½æ–¹æ³•åŠ è½½æ•°æ®
        varr = self._load_data_from_repo(data_key)
        
        if varr is None:
            print(f"âŒ è­¦å‘Š: æ­¥éª¤ '{step_name}' å¯¹åº”çš„å¯è§†åŒ–æ•°æ®é”® '{data_key}' åœ¨æ•°æ®ä»“åº“ä¸­æ‰¾ä¸åˆ°ã€‚")
            
        # è¿”å› xarray.DataArray
        return varr
    def run_load_video_1(self) -> bool:
        """
        æ­¥éª¤ 1: åŠ è½½è§†é¢‘ä¸å»é™¤å…‰æ™•
        å¯¹åº” Minian çš„ load_videos å’Œ remove_glow æ­¥éª¤ã€‚
        """
        step_name = 'load_video_1'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:            
            params = self.get_step_params(step_name)
            
            # --- ä¿®å¤å¼€å§‹: å¤„ç† downsample å‚æ•° ---
            ds_param = params.get('downsample', None)
            
            # å¦‚æœ downsample æ˜¯å­—ç¬¦ä¸² (ä¾‹å¦‚ "dict(frame=1...)" æˆ– "{...}")ï¼Œå°è¯•è½¬æ¢
            if isinstance(ds_param, str):
                try:
                    # å°è¯•è§£æ Python é£æ ¼çš„ dict(...) å­—ç¬¦ä¸²
                    if ds_param.strip().startswith("dict("):
                        ds_param = eval(ds_param)
                    # å°è¯•è§£æ JSON é£æ ¼çš„å­—ç¬¦ä¸²
                    else:
                        ds_param = json.loads(ds_param)
                except Exception as e:
                    self.log_output.append(f"âš ï¸ è­¦å‘Š: downsample å‚æ•°è§£æå¤±è´¥ ('{ds_param}')ï¼Œå°†ä½¿ç”¨ Noneã€‚é”™è¯¯: {e}")
                    ds_param = None
            # --- ä¿®å¤ç»“æŸ ---

            # 1. ä»å‚æ•°ä¸­æå– load_videos éœ€è¦çš„å‚æ•°
            load_params = {
                'pattern': params.get('pattern', r"msCam[0-9]+\.avi$"),
                'dtype': params.get('dtype', 'uint16'),
                'downsample': ds_param, # ä½¿ç”¨å¤„ç†åçš„ ds_param
            }
            
            # 2. è°ƒç”¨ Minian æ ¸å¿ƒå‡½æ•°: load_videos
            self.log_output.append(f"-> æ­£åœ¨åŠ è½½è§†é¢‘ (downsample={ds_param})...")
            varr = load_videos(vpath=self.video_folder, **load_params)
            
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(self.data_path, exist_ok=True)
            
            # è°ƒè¯•ä¿å­˜ (å¯é€‰)
            # varr.to_netcdf(os.path.join(self.data_path, "origin.nc"))

            # 3. è°ƒç”¨ Minian æ ¸å¿ƒå‡½æ•°: remove_glow
            self.log_output.append("-> æ­£åœ¨å»é™¤å…‰æ™•...")
            varr_glow_removed = remove_glow(varr=varr)
            
            # è°ƒè¯•ä¿å­˜ (å¯é€‰)
            # varr_glow_removed.to_netcdf(os.path.join(self.data_path, "varr_glow.nc"))
            
            # 4. ä¿å­˜ç»“æœåˆ°æ•°æ®ä»“åº“
            self._save_data_to_repo(varr_glow_removed, 'varr_glow')
            
            # 5. æ›´æ–° FPS
            if 'frame' in varr.coords and 'fs' in varr.coords['frame'].attrs:
                self.set_video_fps(varr.coords['frame'].attrs['fs'])
            
            self.log_output.append("âœ… è§†é¢‘åŠ è½½ä¸å…‰æ™•å»é™¤å®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except Exception as e:
            import traceback
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            # æ‰“å°è¯¦ç»†å †æ ˆï¼Œæ–¹ä¾¿è°ƒè¯•
            print(traceback.format_exc()) 
            self.update_step_status(step_name, "é”™è¯¯")
            return False


    def run_denoise(self) -> bool:
        """
        æ­¥éª¤ 2: é™å™ª (æ—¶åŸŸå¸¦é€šæ»¤æ³¢/ç©ºåŸŸæ»¤æ³¢)
        æ ¹æ®å‚æ•°ä¸­çš„ 'method' é€‰æ‹©ä¸åŒçš„é™å™ªæ¨¡å¼å’Œå‚æ•°ã€‚
        """
        step_name = 'denoise'
        # ä¿®æ­£è¾“å…¥é”®åï¼šåº”ä¸ load_video_1 çš„è¾“å‡ºé”®ä¸€è‡´
        input_key = 'varr_glow' 
        # ä¿®æ­£è¾“å‡ºé”®åï¼šç”¨äºä¸‹ä¸€æ­¥éª¤ï¼ˆå¦‚è¿åŠ¨æ ¡æ­£æˆ–å»èƒŒæ™¯ï¼‰
        output_key = 'varr_temporally_detrended' 
        
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            varr_in = self._load_data_from_repo(input_key)
            
            if varr_in is None:
                self.log_output.append(f"âš ï¸ è­¦å‘Š: è¾“å…¥æ•°æ® ('{input_key}') æœªæ‰¾åˆ°ï¼Œæ— æ³•æ‰§è¡Œé™å™ªã€‚")
                self.update_step_status(step_name, "è·³è¿‡/é”™è¯¯")
                return False
            if varr_in.dtype != np.float32:
                self.log_output.append(f"-> æ­£åœ¨å°†é™å™ªè¾“å…¥æ•°æ®ç±»å‹ä» {varr_in.dtype} è½¬æ¢ä¸º float32ï¼Œä»¥å…¼å®¹ OpenCVã€‚")
                # xarray.DataArray.astype() ä¼šè‡ªåŠ¨å¤„ç†åº•å±‚çš„ dask æ•°ç»„
                varr_in = varr_in.astype(np.float32)
            # 1. è·å–æ‰€æœ‰é…ç½®å‚æ•°
            params = self.get_step_params(step_name)
            method = params.get('method', 'fft')
            
            # æ‰“å°ä¸€ä¸‹å½“å‰æ‹¿åˆ°çš„æ‰€æœ‰å‚æ•°ï¼Œç”¨äºè°ƒè¯•
            print(f"DEBUG: run_denoise æ¥æ”¶åˆ°çš„å®Œæ•´å‚æ•°: {params}")

            call_kwargs = {}
            prefix_to_match = f"{method}_"
            
            for key, value in params.items():
                if key == 'method':
                    continue
                
                # é€»è¾‘ä¿®æ­£ï¼šä¸¥æ ¼åŒ¹é…å‰ç¼€
                if key.startswith(prefix_to_match):
                    # å‰¥ç¦»å‰ç¼€ï¼š 'fft_low_cut' -> 'low_cut'
                    param_name = key[len(prefix_to_match):]
                    
                    # ç±»å‹å®‰å…¨è½¬æ¢
                    if ('ksize' in param_name or 'wnd' in param_name) and isinstance(value, list):
                        value = tuple(value)
                        
                    call_kwargs[param_name] = value
            
            # æ‰“å°æœ€ç»ˆä¼ é€’ç»™å‡½æ•°çš„å‚æ•°
            print(f"DEBUG: ä¼ é€’ç»™ denoise å‡½æ•°çš„å‚æ•°: {call_kwargs}")
            # 4. æ ¸å¿ƒè°ƒç”¨: denoise
            varr_out = denoise(
                varr_in,
                method=method,
                **call_kwargs
            )
            varr_out.to_netcdf(r"D:\Desktop\ZJU\SRTP\demo\minian_visual_cache\varr_temporally_detrended.nc")
            # 5. ä¿å­˜ç»“æœ
            self._save_data_to_repo(varr_out, output_key)
            
            self.log_output.append(f"âœ… {method} é™å™ªå®Œæˆã€‚æ•°æ®å·²ä¿å­˜åˆ°é”® '{output_key}'ã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except NotImplementedError as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}ã€‚è¯·æ£€æŸ¥å‚æ•° method æ˜¯å¦æ­£ç¡®ã€‚")
            self.update_step_status(step_name, "é”™è¯¯")
            return False
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_background_removal(self) -> bool:
        """
        æ­¥éª¤ 3: å»é™¤èƒŒæ™¯ (ç©ºåŸŸå½¢æ€å­¦æ»¤æ³¢)
        """
        step_name = 'background_removal'
        input_key = 'varr_temporally_detrended'
        output_key = 'varr_final_processed' 
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            varr_in = self._load_data_from_repo(input_key)
            
            if varr_in is None:
                self.log_output.append(f"âš ï¸ è­¦å‘Š: è¾“å…¥æ•°æ® ('{input_key}') æœªæ‰¾åˆ°ï¼Œæ— æ³•æ‰§è¡ŒèƒŒæ™¯å»é™¤ã€‚")
                self.update_step_status(step_name, "è·³è¿‡/é”™è¯¯")
                return False
            print(varr_in.shape)
            print(varr_in.dtype)
            params = self.get_step_params(step_name)
            method = params.get('method', 'tophat') # é»˜è®¤ä¸º tophat
            call_kwargs = {} # ç”¨äºä¼ é€’ç»™ remove_background çš„å‚æ•°å­—å…¸
            
            print(f"DEBUG: run_background_removal æ¥æ”¶åˆ°çš„å®Œæ•´å‚æ•°: {params}")

            self.log_output.append(f"-> æ­£åœ¨æ‰§è¡Œç©ºåŸŸèƒŒæ™¯å»é™¤ã€‚é€šç”¨æ¨¡å¼='{method}'ã€‚")
            
            # éå†å‚æ•°ï¼Œç­›é€‰å¹¶æ¸…ç†é”®å
            prefix_to_match = f"{method}_"
            
            for key, value in params.items():
                if key == 'method':
                    continue
                    
                # æ£€æŸ¥å‚æ•°é”®æ˜¯å¦ä»¥å½“å‰ method ä¸ºå‰ç¼€
                if key.startswith(prefix_to_match):
                    # æå–å‚æ•°åï¼šä¾‹å¦‚ 'tophat_wnd' -> 'wnd'
                    param_name = key[len(prefix_to_match):]
                    
                    # ç‰¹æ®Šç±»å‹å¤„ç†ï¼šwnd å¯èƒ½éœ€è¦ä»åˆ—è¡¨è½¬ä¸ºå…ƒç»„
                    if ('wnd' in param_name or 'ksize' in param_name) and isinstance(value, list):
                        value = tuple(value)
                    
                    call_kwargs[param_name] = value
                    
            print(f"DEBUG: ä¼ é€’ç»™ remove_background å‡½æ•°çš„å‚æ•°: {call_kwargs}")
            
            # æ ¸å¿ƒè°ƒç”¨: ä½¿ç”¨æ‚¨æä¾›çš„ remove_background å‡½æ•°
            varr_out = remove_background(
                varr_in,
                method=method,
                **call_kwargs # ä½¿ç”¨è§£åŒ…çš„å‚æ•°
            )
            varr_out.to_netcdf(r"D:\Desktop\ZJU\SRTP\demo\minian_visual_cache\varr_final_processed.nc")
            
            self._save_data_to_repo(varr_out, output_key)
            self.log_output.append("âœ… ç©ºåŸŸèƒŒæ™¯å»é™¤å®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_motion_correction(self) -> bool:
        """
        æ­¥éª¤ 4: è¿åŠ¨æ ¡æ­£
        å¯¹åº” Minian çš„ estimate_motion å’Œ apply_shifts æ­¥éª¤ã€‚
        """
        step_name = 'motion_correction'
        input_key = 'varr_final_processed' 
        output_key = 'varr_mc'
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            varr_in = self._load_data_from_repo(input_key)
            params = self.get_step_params(step_name)
            print(params)
            # 1. ä¼°è®¡è¿åŠ¨
            self.log_output.append("-> æ­£åœ¨ä¼°è®¡è¿åŠ¨ä½ç§»...")
            shifts = estimate_motion(varr_in, **params.get('estimate_motion_kwargs', {}))
            self._save_data_to_repo(shifts, 'shifts') # ä¿å­˜ä½ç§»æ•°æ®
            
            # 2. åº”ç”¨è¿åŠ¨ä½ç§»
            self.log_output.append("-> æ­£åœ¨åº”ç”¨è¿åŠ¨æ ¡æ­£...")
            varr_mc = apply_shifts(varr_in, shifts, **params.get('apply_shifts_kwargs', {}))
            
            self.steps_results[step_name] = (varr_in, varr_mc)
            
            # è¾“å‡ºvarr_mcçš„ç±»å‹
            print(type(varr_mc))
            # è¾“å‡ºvarr_mcçš„shape
            print(varr_mc.shape)
            varr_mc.to_netcdf(r"D:\Desktop\ZJU\SRTP\demo\minian_visual_cache\mc.nc")

            # np.save(varr_mc,r"D:\Desktop\ZJU\SRTP\demo\minian_visual_cache\mc.npy")
            
            self._save_data_to_repo((varr_in,varr_mc), output_key)
            self.log_output.append("âœ… è¿åŠ¨æ ¡æ­£å®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            # æ‰“å°å®Œæ•´çš„é”™è¯¯è¿½è¸ªæ ˆ
            error_trace = traceback.format_exc()
            
            # æ‰“å°ç®€çŸ­æ‘˜è¦
            self.log_output.append(f"âŒ è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {type(e).__name__} - {e}")
            # æ‰“å°è¯¦ç»†è¿½è¸ª
            print(f"--- è¯¦ç»†è¿½è¸ªçº¿ ---\n{error_trace}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{error_trace}")
            
            # ä¿®å¤ TypeError å´©æºƒï¼šç¡®ä¿åœ¨å¤±è´¥æ—¶å°†ç»“æœè®¾ç½®ä¸º None
            self.steps_results[step_name] = None 
            
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    # æ–‡ä»¶: minian_processor.py
    # å‡½æ•°: run_seeds_init

    def run_seeds_init(self) -> bool:
        """
        æ­¥éª¤ 5: åˆå§‹åŒ–ç§å­ (Seeds Initialization)
        ä½¿ç”¨ seeds_init å‡½æ•°è®¡ç®—åˆå§‹ç©ºé—´ç»„ä»¶çš„å€™é€‰åŒºåŸŸï¼ˆç§å­ï¼‰ã€‚
        """
        step_name = 'seeds_init'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # ğŸš¨ ç§»é™¤å¯¹ os.environ["MINIAN_INTERMEDIATE"] çš„è®¾ç½®å’Œæ£€æŸ¥ï¼Œç”± UI è´Ÿè´£

            # 1. åŠ è½½è¿åŠ¨æ ¡æ­£åçš„è§†é¢‘ (ä¿®æ­£å¯¼å…¥è¯­å¥)
            varr_mc_raw = self._load_data_from_repo('varr_mc') 
            
            if isinstance(varr_mc_raw, tuple) and len(varr_mc_raw) == 2:
                varr_in_for_seeds = varr_mc_raw[1]
            else:
                varr_in_for_seeds = varr_mc_raw
            
            if varr_in_for_seeds is None:
                self.log_output.append("âš ï¸ è­¦å‘Š: è¿åŠ¨æ ¡æ­£åçš„è§†é¢‘æ•°æ® ('varr_mc') æœªæ‰¾åˆ°ï¼Œæ— æ³•æ‰§è¡Œç§å­åˆå§‹åŒ–ã€‚")
                self.update_step_status(step_name, "è·³è¿‡/é”™è¯¯")
                return False

            # ğŸš¨ ä¿®å¤å¯è§†åŒ–ï¼šå­˜å‚¨ç”¨äºå¯è§†åŒ–èƒŒæ™¯çš„è§†é¢‘æ•°ç»„ (ç”¨äº UI è·å–èƒŒæ™¯è§†é¢‘)
            # self._save_data_to_repo(varr_in_for_seeds, 'varr_seeds') 
            self._save_data_to_repo(varr_in_for_seeds, 'video_for_seeds_vis')
            
            params = self.get_step_params(step_name)
            print(f"DEBUG: run_seeds_init æ¥æ”¶åˆ°çš„å‚æ•°: {params}")

            # 2. ç¡®å®šæ–¹æ³•
            method = params.get('method', 'rolling')
            
            # 3. å‡†å¤‡å‚æ•°å­—å…¸
            # ä¸è¦ä½¿ç”¨ç¡¬ç¼–ç çš„ DEFAULT_PARAMS æ¥åˆå§‹åŒ–ï¼Œè€Œæ˜¯æ ¹æ®å‡½æ•°ç­¾ååŠ¨æ€æ„å»º
            # æˆ–è€…å…ˆå®šä¹‰é»˜è®¤å€¼ï¼Œç„¶åç”¨ params è¦†ç›–å®ƒ
            
            # é»˜è®¤å€¼å®šä¹‰ (ä»…ä½œä¸ºå…œåº•ï¼Œè‹¥ config ä¸­æœ‰å€¼åˆ™ä¼šè¢«è¦†ç›–)
            params_to_pass = {
                'wnd_size': 1000, 
                'stp_size': 500, 
                'max_wnd': 15, 
                'diff_thres': 3,
                'method': method
            }
            
            prefix_to_match = f"{method}_"
            
            for key, value in params.items():
                if key == 'method': continue
                
                # å¦‚æœå‚æ•°å¸¦å‰ç¼€ (å¦‚ rolling_wnd_size)ï¼Œå‰¥ç¦»å‰ç¼€å¹¶è¦†ç›–é»˜è®¤å€¼
                if key.startswith(prefix_to_match):
                    param_name = key[len(prefix_to_match):]
                    params_to_pass[param_name] = value
                
                # å¦‚æœå‚æ•°æœ¬èº«å°±æ˜¯æ— å‰ç¼€çš„é€šç”¨å‚æ•° (å¦‚æŸäº›é…ç½®å¯èƒ½ç›´æ¥å­˜äº† wnd_size)ï¼Œä¹Ÿå…è®¸è¦†ç›–
                elif key in params_to_pass:
                    params_to_pass[key] = value

            print(f"DEBUG: æœ€ç»ˆä¼ é€’ç»™ seeds_init çš„å‚æ•°: {params_to_pass}")

            # 4. è°ƒç”¨å‡½æ•°
            seeds = seeds_init(varr_in_for_seeds, **params_to_pass)
                
            # 5. æ£€æŸ¥ seeds_init çš„è¿”å›ç»“æœ
            if seeds is None or (hasattr(seeds, 'empty') and seeds.empty):
                self.log_output.append("âŒ æ ¸å¿ƒå‡½æ•° seeds_init è¿è¡Œå¤±è´¥æˆ–æœªæ‰¾åˆ°ä»»ä½•ç§å­ã€‚è¯·æ£€æŸ¥å‚æ•°è®¾ç½®ã€‚")
                self.update_step_status(step_name, "é”™è¯¯")
                return False
                
            self.log_output.append(
                f"-> ç§å­åˆå§‹åŒ–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(seeds)} ä¸ªå€™é€‰åŒºåŸŸã€‚"
            )

            # è®¡ç®—æœ€å¤§æŠ•å½±ä½œä¸ºç§å­å¯è§†åŒ–èƒŒæ™¯
            self.log_output.append("-> æ­£åœ¨è®¡ç®—ç§å­å¯è§†åŒ–çš„æœ€å¤§æŠ•å½±å›¾...")
            max_proj = varr_in_for_seeds.max(dim='frame').compute()
            
            # ä¿å­˜ç§å­æ•°æ®åˆ°'varr_seeds' (pandas.DataFrame)
            self._save_data_to_repo(seeds, 'varr_seeds')
            
            # ä¿å­˜æœ€å¤§æŠ•å½±å›¾åˆ°'max_proj_seeds' (xarray.DataArray)
            self._save_data_to_repo(max_proj, 'max_proj_seeds')
            
            self.log_output.append("âœ… åˆå§‹ç§å­ (seeds) å·²ä¿å­˜ã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_noise_freq_exploration(self) -> tuple:
        """
        å™ªå£°é¢‘ç‡æ¢ç´¢ä¸PNRæ›²çº¿è®¡ç®— (å·²ä¿®æ­£ç‰ˆæœ¬)
        
        - ç¡®ä¿è°ƒç”¨ smooth_sig æ—¶ä¼ å…¥äº† 'fs'ã€‚
        - (å·²ä¿®æ­£) ç¡®ä¿ä» `varr_seeds` (ä¸Šä¸€æ­¥çš„ç§å­) ä¸­é‡‡æ ·ï¼Œè€Œä¸æ˜¯ç”Ÿæˆéšæœºåæ ‡ã€‚
        """

        step_name = 'noise_freq_exploration'
        input_key = 'varr_temporally_detrended'
        # ğŸ”´ ä¿®æ­£ 1: å£°æ˜ç§å­çš„è¾“å…¥é”®
        seeds_input_key = 'varr_seeds' 

        try:
            # ==== Step 1: å‚æ•°ä¸æ•°æ®å‡†å¤‡ ====
            self.update_step_status(step_name, "è¿è¡Œä¸­")
            print(f"å¼€å§‹è¿è¡Œ")
            varr_in = self._load_data_from_repo(input_key) # (frame, height, width)
            varr_in = varr_in.chunk(dict(frame=-1))
            
            if varr_in is None:
                raise ValueError("æ— æ³•åŠ è½½è¾“å…¥æ•°æ® (varr_in)ã€‚")
                
            # ğŸ”´ ä¿®æ­£ 2: åŠ è½½ `seeds_init` æ­¥éª¤ç”Ÿæˆçš„çœŸå®ç§å­
            seeds_all_xr = self._load_data_from_repo(seeds_input_key)
            if seeds_all_xr is None:
                raise ValueError(f"æ— æ³•åŠ è½½ç§å­æ•°æ® ('{seeds_input_key}')ã€‚è¯·å…ˆè¿è¡Œ 'seeds_init' æ­¥éª¤ã€‚")

            # ğŸ”´ ä¿®æ­£ 3: å°† Xarray ç§å­è½¬æ¢å› DataFrame ä»¥ä¾¿é‡‡æ ·
            # (åŸºäº initialization.py ä¸­ seeds_init çš„è¿”å›ç»“æ„)
            try:
                seeds_df = pd.DataFrame({
                    'height': seeds_all_xr.coords['height'].values,
                    'width': seeds_all_xr.coords['width'].values
                })
            except Exception as e:
                print(f"è½¬æ¢ç§å­æ•°æ®å¤±è´¥: {e}. seeds_all_xr ç»“æ„: {seeds_all_xr}")
                raise

            n_frames, height, width = varr_in.shape
            print(f"æ•°æ®å‡†å¤‡å®Œæˆ (f, h, w): {varr_in.shape}")
            
            # å‚æ•°è¯»å–
            params = self.get_step_params(step_name)
            noise_freq_candidates = np.array(params.get('noise_freq_list'))
            self.log_output.append(f"-> æ¢ç´¢å™ªå£°é¢‘ç‡: {noise_freq_candidates} Hz")
            print(f"å‚æ•°æƒ…å†µ: {params}")
            print(f"æ¢ç´¢å™ªå£°é¢‘ç‡: {noise_freq_candidates} Hz")
            fs = float(params.get('fs', 30.0))
            
            # ğŸ”´ ä¿®æ­£ 4: ä»çœŸå®çš„ç§å­ DataFrame ä¸­é‡‡æ ·
            n_samples_req = int(params.get('n_samples', 6)) # æ‚¨è¦æ±‚çš„ 6
            
            if len(seeds_df) > n_samples_req:
                # ä»çœŸå®ç§å­ä¸­éšæœºæŠ½å– n_samples_req ä¸ª
                sample_seeds = seeds_df.sample(n=n_samples_req, random_state=42)
            else:
                # å¦‚æœæ€»ç§å­æ•°å°‘äºè¦æ±‚ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰ç§å­
                sample_seeds = seeds_df
            
            # æ›´æ–° n_samples ä¸ºå®é™…é‡‡æ ·çš„æ•°é‡
            n_samples = len(sample_seeds)
            print(f"å·²ä» {len(seeds_df)} ä¸ªæ€»ç§å­ä¸­æˆåŠŸé‡‡æ · {n_samples} ä¸ªã€‚")
            

            print(f"å¼€å§‹è®¡ç®—")
            # ==== Step 2: æœ€ä½³é¢‘ç‡æ¢ç´¢ (åŸºäºæ‰€æœ‰åƒç´ ç‚¹) ====
            best_pnr_mean_all = -np.inf
            best_noise_freq = None
            all_freq_pnr_means = {}
            print(f"å¼€å§‹å¾ªç¯")
            
            for freq in noise_freq_candidates:
                # 1. åˆ†ç¦»ä¿¡å·ä¸å™ªå£°
                print(f"è¿›å…¥å¾ªç¯ï¼Œé¢‘ç‡: {freq} Hz")
                signal_all = smooth_sig(varr_in, freq, fs, method="butter", btype="low")
                print(f"signal_all.shape {signal_all.shape}")
                noise_all = smooth_sig(varr_in, freq, fs, method="butter", btype="high")
                print(f"noise_all.shape {noise_all.shape}")
                
                 # è®¡ç®—çœŸæ­£çš„ä¿¡å·å¹…åº¦ (Amplitude)
                signal_baseline = signal_all.min('frame') 
                signal_amplitude = signal_all.max('frame') - signal_baseline
                
                # PNR = å¹…åº¦ / å™ªå£°æ ‡å‡†å·®
                pnr_all = signal_amplitude / noise_all.std('frame')
                
                # 3. è®¡ç®— PNR å‡å€¼
                print(f"DEBUG: å¼€å§‹è®¡ç®—é¢‘ç‡ {freq} çš„ PNR å‡å€¼...")
                pnr_mean_current_float = pnr_all.mean().compute().item()
                print(f"DEBUG: é¢‘ç‡ {freq} çš„ PNR å‡å€¼è®¡ç®—å®Œæˆ: {pnr_mean_current_float:.4f}")
                all_freq_pnr_means[freq] = pnr_mean_current_float

                print(f"For frequency {freq}, the PNR mean is {pnr_mean_current_float:.4f}.Current best is {best_pnr_mean_all:.4f}.")
                self.log_output.append(f"For frequency {freq}, the PNR mean is {pnr_mean_current_float:.4f}.Current best is {best_pnr_mean_all:.4f}.")
                
                
                # 4. ç­›é€‰æœ€ä½³é¢‘ç‡
                if pnr_mean_current_float > best_pnr_mean_all:
                    best_pnr_mean_all = pnr_mean_current_float
                    best_noise_freq = freq

            if best_noise_freq is None:
                raise RuntimeError("æœªèƒ½ç¡®å®šæœ€ä½³å™ªå£°é¢‘ç‡ã€‚")

            # self.log_output.append(f"æœ€ä½³å™ªå£°æˆªæ­¢é¢‘ç‡ç¡®å®šä¸º: {best_noise_freq} Hz (æ‰€æœ‰åƒç´ ç‚¹PNRå‡å€¼: {best_pnr_mean_all:.4f})")
            print(f"æœ€ä½³å™ªå£°æˆªæ­¢é¢‘ç‡ç¡®å®šä¸º: {best_noise_freq} Hz (æ‰€æœ‰åƒç´ ç‚¹PNRå‡å€¼: {best_pnr_mean_all:.4f})")
            self.save_best_freq_to_params(best_noise_freq) 
            print(f"æœ€ä½³å™ªå£°é¢‘ç‡å·²ä¿å­˜")
            
            # ==== Step 3: åŸºäºæœ€ä½³é¢‘ç‡è®¡ç®—ç§å­ç‚¹æ•°æ® (ç”¨äºè¿”å›) ====
            sample_coords_xr = sample_seeds.to_xarray().rename({'index': 'sample'})

            # b. ä½¿ç”¨ .sel å’Œ DataArray è¿›è¡Œç‚¹å¯¹ç‚¹ç´¢å¼•
            #    è¿™å°†è¿”å›ä¸€ä¸ª (frame, sample) çš„ DataArray
            varr_samples_sel = varr_in.sel(
                height=sample_coords_xr["height"], 
                width=sample_coords_xr["width"]
            )
            
            # c. è½¬æ¢ä¸º (sample, frame) ä»¥ä¾¿ smooth_sig å¤„ç†
            varr_samples_chk = varr_samples_sel.transpose('sample', 'frame')
            
            print(f"ç§å­ç‚¹æ•°æ®æå–å®Œæˆï¼Œå½¢çŠ¶: {varr_samples_chk.shape}") # (åº”ä¸º 6, 600)
            
            # 1. å†æ¬¡åˆ†ç¦»ä¿¡å·ä¸å™ªå£° (ä»…é’ˆå¯¹ç§å­ç‚¹)
            signal_best = smooth_sig(varr_samples_chk, best_noise_freq, fs, method="butter", btype="low").compute()
            noise_best = smooth_sig(varr_samples_chk, best_noise_freq, fs, method="butter", btype="high").compute()

            # 2. è®¡ç®—ç§å­ç‚¹çš„ PNR
            if not isinstance(signal_best, xr.DataArray):
                 signal_best = xr.DataArray(signal_best, dims=['sample', 'frame'])
                 noise_best = xr.DataArray(noise_best, dims=['sample', 'frame'])

            signal_best_baseline = signal_best.mean('frame')
            pnr_best = (signal_best.max('frame') - signal_best_baseline) / noise_best.std('frame')
            
            # ==== Step 4: è½¬æ¢ç»“æ„ï¼Œå¹¶ç¡®ä¿è¿”å›æ ¼å¼ä¸å˜ ====
            
            # 1. è®¡ç®—ä¿¡å·çš„åŸºçº¿ (æ¯ä¸ªæ ·æœ¬çš„å‡å€¼)
            # signal_best å½¢çŠ¶æ˜¯ (samples, frames)
            baselines = signal_best.min(dim='frame') 
            
            # 2. å°†å™ªå£°æ•°æ®åŠ ä¸Šè¿™ä¸ªåŸºçº¿ï¼Œä½¿å…¶åœ¨è§†è§‰ä¸Šä¸ä¿¡å·é‡åˆ
            # æ³¨æ„ï¼šåˆ©ç”¨å¹¿æ’­æœºåˆ¶ (samples, frames) + (samples,)
            noise_best_visual = noise_best + baselines
            
            # 3. å¯¼å‡ºæ•°æ®
            signals_arr = np.expand_dims(signal_best.values, axis=0)
            # ä½¿ç”¨è°ƒæ•´è¿‡åŸºçº¿çš„å™ªå£°æ•°æ®ç”¨äºæ˜¾ç¤º
            noises_arr = np.expand_dims(noise_best_visual.values, axis=0) 
            pnrs_values = np.expand_dims(pnr_best.values, axis=0)
            
            pnrs_mean = np.array([np.mean(pnr_best.values)]) 
            
            noise_freq_list = np.array([best_noise_freq])
            print(f"æ•°æ®è½¬æ¢å®Œæˆ")
            
            # ==== Step 5: è¿”å›ç»“æœ ====
            self.update_step_status(step_name, "å®Œæˆ âœ…")
            return (
                "æˆåŠŸ",
                sample_seeds, # sample_seeds ç°åœ¨æ˜¯åŒ…å« (height, width) çš„ DataFrame
                pnrs_mean,
                pnrs_values,
                signals_arr,
                noises_arr,
                noise_freq_list,
                fs
            )

        except Exception as e:
            # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆä»¥ä¾¿è°ƒè¯•
            import traceback
            traceback.print_exc() 
            
            self.update_step_status(step_name, "å¤±è´¥ âŒ")
            self.log_output.append(f"[ERROR] å™ªå£°é¢‘ç‡æ¢ç´¢å¤±è´¥: {str(e)}")
            print(f"[ERROR] å™ªå£°é¢‘ç‡æ¢ç´¢å¤±è´¥: {str(e)}")
            return ("å¤±è´¥", None, None, None, None, None, None, None)

    # ... (save_best_freq_to_params ä¿æŒä¸å˜) ...
    # å ä½å‡½æ•°ï¼ˆæ‚¨è¦æ±‚æˆ‘å…ˆé‚£ä¸€ä¸ªå‡½æ•°å¡«å……ï¼Œè¿™ä¸ªåé¢å†ç»™å‡ºï¼‰
    def save_best_freq_to_params(self, freq: float):
        """
        å°†æœ€ä½³é¢‘ç‡ä¿å­˜åˆ°åç»­æ­¥éª¤çš„å‚æ•°ä¸­ã€‚
        """
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ç±»ä¼¼ self.set_param('next_step_name', 'noise_freq', freq) çš„æ–¹æ³•
        print(f"[INFO] æœ€ä½³é¢‘ç‡ {freq} Hz å·²ä¿å­˜ä¾›åç»­æ­¥éª¤ä½¿ç”¨ã€‚")
        # è¾…åŠ©å‡½æ•° (ä» visualization.py å¤åˆ¶è¿‡æ¥ï¼Œç¡®ä¿ processor å†…éƒ¨å¯ç”¨)
        
    def _convert_seeds_to_df(self,seeds_data: Union[pd.DataFrame, xr.DataArray]) -> pd.DataFrame:
        """è¾…åŠ©å‡½æ•°ï¼šå°† XArray ç§å­è½¬æ¢ä¸ºè§„èŒƒçš„ DataFrameã€‚"""
        if isinstance(seeds_data, xr.DataArray):
            try:
                seeds_df = pd.DataFrame({
                    'height': seeds_data.coords['height'].values,
                    'width': seeds_data.coords['width'].values
                })
            except KeyError:
                seeds_df = seeds_data.rename("seeds").to_dataframe().reset_index()
                if 'height' not in seeds_df.columns or 'width' not in seeds_df.columns:
                    if 'dim_0' in seeds_df.columns and 'dim_1' in seeds_df.columns:
                        seeds_df['height'] = seeds_df['dim_0']
                        seeds_df['width'] = seeds_df['dim_1']
                    else:
                        raise ValueError("è¾“å…¥DataArrayå¿…é¡»åŒ…å«height/widthæˆ–dim_0/dim_1ç»´åº¦")
            return seeds_df
        else:
            return seeds_data.copy()

    def run_peak_noise_ratio_refine(self) -> bool:
        """
        ...
        """
        step_name = 'peak_noise_ratio_refine'
        input_key = 'varr_seeds' 
        
        output_key_kept = 'seeds_pnr_kept'
        output_key_removed = 'seeds_pnr_removed'
        
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            varr_mc_tuple = self._load_data_from_repo('varr_mc')
            if isinstance(varr_mc_tuple, tuple) and len(varr_mc_tuple) == 2:
                varr_mc = varr_mc_tuple[1]
            else:
                varr_mc = varr_mc_tuple
                
            seeds_init_xr = self._load_data_from_repo(input_key)
            params = self.get_step_params(step_name)
            
            # ğŸ”´ ä¿®æ­£ 1: è·å–é‡‡æ ·é¢‘ç‡ (fs)
            fs = self.get_video_fps()
            
            # ä¸¥æ ¼å‚æ•°éªŒè¯
            valid_params = {}
            for k, v in params.items():
                clean_key = k
                # ğŸ”´ ä¿®æ­£ 2: å…è®¸ 'fs' (ä½† 'fs' ä¸åº”æ¥è‡ªUI)
                if clean_key in ['noise_freq', 'thres']:  
                    valid_params[clean_key] = v
            
            # ğŸ”´ ä¿®æ­£ 3: å°† processor çš„ 'fs' å¼ºè¡Œæ³¨å…¥å‚æ•°
            valid_params['fs'] = fs
            
            self.log_output.append(f"-> åŸå§‹å‚æ•°: {params}")
            self.log_output.append(f"-> æœ‰æ•ˆå‚æ•° (å«fs): {valid_params}")
            
            if not valid_params.get('noise_freq'):
                self.log_output.append("âš ï¸ è­¦å‘Š: noise_freqå‚æ•°ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼0.25")
                valid_params['noise_freq'] = 0.25
                
            # å‡†å¤‡æ•°æ®æ ¼å¼
            self.log_output.append("-> æ­£åœ¨å‡†å¤‡æ•°æ®æ ¼å¼...")
            
            # å¤„ç†varr_mc (xarrayå¯¹è±¡)
            if hasattr(varr_mc, 'chunk'):
                varr_mc = varr_mc.chunk({'height': -1, 'width': -1, 'frame': -1}).persist()
            
            # ğŸ”´ ä¿®æ­£: ç¡®ä¿ seeds_init æ˜¯ pandas.DataFrame (ä½¿ç”¨ visualization.py ä¸­çš„è¾…åŠ©å‡½æ•°é€»è¾‘)
            self.log_output.append(f"-> seeds_initç±»å‹: {type(seeds_init_xr)}")
            try:
                seeds_init_df = self._convert_seeds_to_df(seeds_init_xr)
            except Exception as e:
                self.log_output.append(f"âŒ æ— æ³•è½¬æ¢ 'varr_seeds' ä¸º DataFrame: {e}")
                raise
            
            self.log_output.append("-> æ­£åœ¨è®¡ç®— PNR å¹¶ç²¾ä¿®ç§å­ç‚¹...")
            try:
                # pnr_refine (from initialization.py) è¿”å›ä¸€ä¸ª DataFrame
                # åŒ…å«ä¸€ä¸ªå¸ƒå°”åˆ— "mask_pnr"
                seeds_with_mask, pnrs, gmm = pnr_refine(
                    varr_mc,
                    seeds_init_df, # ä¼ å…¥ DataFrame
                    **valid_params
                )
            except Exception as e:
                self.log_output.append(f"âŒ PNRè®¡ç®—å¤±è´¥: {str(e)}")
                print(f"âŒ PNRè®¡ç®—å¤±è´¥: {str(e)}")
                raise
            
            # ğŸ”´ ä¿®æ­£: å°†ç§å­åˆ†ä¸º "ä¿ç•™" å’Œ "ç§»é™¤"
            if 'mask_pnr' not in seeds_with_mask.columns:
                self.log_output.append(f"âŒ é”™è¯¯: 'pnr_refine' æœªè¿”å› 'mask_pnr' åˆ—ã€‚")
                raise ValueError("pnr_refineçš„è¾“å‡ºç¼ºå°‘'mask_pnr'åˆ—")

            seeds_kept = seeds_with_mask[seeds_with_mask['mask_pnr'] == True]
            seeds_removed = seeds_with_mask[seeds_with_mask['mask_pnr'] == False]
            
            # ğŸ”´ ä¿®æ­£: ä¿å­˜ä¸¤ç»„åˆ†ç¦»çš„ç§å­
            self._save_data_to_repo(seeds_kept, output_key_kept)
            self._save_data_to_repo(seeds_removed, output_key_removed)
            
            # (å¯é€‰) ä¿å­˜ PNR å€¼å’Œ GMM æ¨¡å‹
            self._save_data_to_repo(pnrs, 'pnrs')
            self._save_data_to_repo(gmm, 'gmm_model') 
            
            self.log_output.append(f"âœ… PNR ç²¾ä¿®å®Œæˆã€‚")
            self.log_output.append(f"-> {len(seeds_kept)} ä¸ªç§å­è¢«ä¿ç•™ (ç™½è‰²)ã€‚")
            self.log_output.append(f"-> {len(seeds_removed)} ä¸ªç§å­è¢«ç§»é™¤ (çº¢è‰²)ã€‚")
            print(f"âœ… PNR ç²¾ä¿®å®Œæˆã€‚ä¿ç•™: {len(seeds_kept)}, ç§»é™¤: {len(seeds_removed)}")
            
            # ğŸ”´ ä¿®æ­£: ç§»é™¤æ—§çš„ matplotlib å¯è§†åŒ–ä»£ç 
            # (ä» "ç”Ÿæˆå¯è§†åŒ–ç»“æœ..." åˆ° "self.log_output.append(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {str(e)}")" 
            #  çš„æ‰€æœ‰ä»£ç å—éƒ½åº”è¢«åˆ é™¤, å› ä¸ºç°åœ¨ç”± main_pipeline_window.py å¤„ç†)
            
            self.update_step_status(step_name, "å·²å®Œæˆ")
            
            # ğŸ”´ ä¿®æ­£: è¿”å›ç®€å•çš„ True
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(traceback.format_exc())
            self.update_step_status(step_name, "é”™è¯¯")
            return False



    def run_ks_refine(self) -> bool:
        """
        æ­¥éª¤ 7: KS æ£€éªŒç²¾ä¿®
        (å·²ä¿®æ”¹ä¸ºåœ¨ 'pnr_refine' æ­¥éª¤çš„ç»“æœä¸Šè¿›è¡Œç­›é€‰ï¼Œå¹¶ä¿å­˜ 'kept' å’Œ 'removed' ç§å­)
        """
        step_name = 'ks_refine'
        
        # ğŸ”´ ä¿®æ­£ 1: è¾“å…¥é”®å¿…é¡»æ˜¯ PNR æ­¥éª¤ä¿ç•™çš„ç§å­
        input_key = 'seeds_pnr_kept' 
        
        # ğŸ”´ ä¿®æ­£ 2: å®šä¹‰æ–°çš„ã€å”¯ä¸€çš„è¾“å‡ºé”®
        output_key_kept = 'seeds_ks_kept'
        output_key_removed = 'seeds_ks_removed'
        
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            # 1. åŠ è½½è¿åŠ¨æ ¡æ­£è§†é¢‘ (ç”¨äº ks_refine)
            varr_mc_tuple = self._load_data_from_repo('varr_mc')
            if isinstance(varr_mc_tuple, tuple) and len(varr_mc_tuple) == 2:
                varr_mc = varr_mc_tuple[1]
            else:
                varr_mc = varr_mc_tuple

            if varr_mc is None:
                 raise ValueError("æ— æ³•åŠ è½½ 'varr_mc' æ•°æ®ã€‚")
            
            self.log_output.append("-> æ­£åœ¨é‡åˆ†å— (Rechunking) 'frame' ç»´åº¦...")
            varr_mc = varr_mc.chunk({'frame': -1})
            
            # 2. åŠ è½½ PNR æ­¥éª¤ä¿ç•™çš„ç§å­ (DataFrame)
            seeds_to_test = self._load_data_from_repo(input_key)
            if seeds_to_test is None:
                raise ValueError(f"æ— æ³•åŠ è½½ä¸Šä¸€æ­¥çš„ç§å­æ•°æ® ('{input_key}')ã€‚è¯·å…ˆè¿è¡Œ 'peak_noise_ratio_refine' æ­¥éª¤ã€‚")
            if not isinstance(seeds_to_test, pd.DataFrame):
                self.log_output.append(f"-> è­¦å‘Š: è¾“å…¥çš„ç§å­ä¸æ˜¯ DataFrame (ç±»å‹: {type(seeds_to_test)})ï¼Œå°è¯•è½¬æ¢...")
                seeds_to_test = self._convert_seeds_to_df(seeds_to_test)

            # 3. è·å–å‚æ•° (ks_refine åªæ¥å— 'sig')
            params = self.get_step_params(step_name)
            valid_params = {}
            if 'sig' in params:
                valid_params['sig'] = float(params['sig'])
            
            self.log_output.append(f"-> æ­£åœ¨å¯¹ {len(seeds_to_test)} ä¸ªç§å­ä½¿ç”¨ KS æ£€éªŒç²¾ä¿®...")
            self.log_output.append(f"-> æœ‰æ•ˆå‚æ•°: {valid_params}")

            # 4. è°ƒç”¨æ ¸å¿ƒå‡½æ•°
            # ks_refine è¿”å›ä¸€ä¸ª *æ–°çš„* DataFrameï¼Œå…¶ä¸­æ·»åŠ äº† 'mask_ks' åˆ—
            seeds_with_mask = ks_refine(varr_mc, seeds_to_test, **valid_params)
            
            # 5. ğŸ”´ ä¿®æ­£ 3: æ ¹æ® 'mask_ks' åˆ†ç¦»ç§å­
            if 'mask_ks' not in seeds_with_mask.columns:
                self.log_output.append(f"âŒ é”™è¯¯: 'ks_refine' æœªè¿”å› 'mask_ks' åˆ—ã€‚")
                raise ValueError("ks_refine çš„è¾“å‡ºç¼ºå°‘ 'mask_ks' åˆ—")

            # æ³¨æ„ï¼šks_refine çš„ 'mask_ks' æ˜¯ True è¡¨ç¤º *é€šè¿‡* (p-value < sig)
            seeds_kept = seeds_with_mask[seeds_with_mask['mask_ks'] == True]
            seeds_removed = seeds_with_mask[seeds_with_mask['mask_ks'] == False]
            
            # 6. ä¿å­˜ä¸¤ç»„åˆ†ç¦»çš„ç§å­
            self._save_data_to_repo(seeds_kept, output_key_kept)
            self._save_data_to_repo(seeds_removed, output_key_removed)

            self.log_output.append(f"âœ… KS æ£€éªŒä¸è¿‡æ»¤å®Œæˆã€‚")
            self.log_output.append(f"-> {len(seeds_kept)} ä¸ªç§å­è¢«ä¿ç•™ (ç™½è‰²)ã€‚")
            self.log_output.append(f"-> {len(seeds_removed)} ä¸ªç§å­è¢«ç§»é™¤ (çº¢è‰²)ã€‚")
            print(f"âœ… KS æ£€éªŒå®Œæˆã€‚ä¿ç•™: {len(seeds_kept)}, ç§»é™¤: {len(seeds_removed)}")

            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(traceback.format_exc())
            self.update_step_status(step_name, "é”™è¯¯")
            return False


    def run_merge_seeds(self) -> bool:
        """
        æ­¥éª¤ 8: åˆå¹¶ç§å­ç‚¹
        (å·²ä¿®æ”¹ä¸ºåœ¨ 'ks_refine' æ­¥éª¤çš„ç»“æœä¸Šè¿›è¡Œç­›é€‰ï¼Œå¹¶ä¿å­˜ 'kept' å’Œ 'removed' ç§å­)
        """
        step_name = 'merge_seeds'
        
        # ğŸ”´ ä¿®æ­£ 1: è¾“å…¥é”®
        input_key = 'seeds_ks_kept'
        
        # ğŸ”´ ä¿®æ­£ 2: å”¯ä¸€çš„è¾“å‡ºé”®
        output_key_kept = 'seeds_merged_kept'
        output_key_removed = 'seeds_merged_removed'
        
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            # 1. åŠ è½½è§†é¢‘
            varr_mc_tuple = self._load_data_from_repo('varr_mc')
            if isinstance(varr_mc_tuple, tuple) and len(varr_mc_tuple) == 2:
                varr_mc = varr_mc_tuple[1]
            else:
                varr_mc = varr_mc_tuple

            # ğŸ”´ ä¿®æ­£ 3: Rechunk 'frame' ç»´åº¦
            # (seeds_merge -> adj_corr -> smooth_corr -> filt_fft 
            #  éƒ½éœ€è¦å®Œæ•´çš„ 'frame' ç»´åº¦)
            if varr_mc is None:
                 raise ValueError("æ— æ³•åŠ è½½ 'varr_mc' æ•°æ®ã€‚")
            self.log_output.append("-> æ­£åœ¨é‡åˆ†å— (Rechunking) 'frame' ç»´åº¦...")
            varr_mc = varr_mc.chunk({'frame': -1})

            # 2. åŠ è½½ 'ks_refine' ä¿ç•™çš„ç§å­
            seeds_to_merge = self._load_data_from_repo(input_key)
            if seeds_to_merge is None:
                raise ValueError(f"æ— æ³•åŠ è½½ä¸Šä¸€æ­¥çš„ç§å­æ•°æ® ('{input_key}')ã€‚è¯·å…ˆè¿è¡Œ 'ks_refine' æ­¥éª¤ã€‚")
            if not isinstance(seeds_to_merge, pd.DataFrame):
                self.log_output.append(f"-> è­¦å‘Š: è¾“å…¥çš„ç§å­ä¸æ˜¯ DataFrame (ç±»å‹: {type(seeds_to_merge)})ï¼Œå°è¯•è½¬æ¢...")
                seeds_to_merge = self._convert_seeds_to_df(seeds_to_merge) # ä½¿ç”¨è¾…åŠ©å‡½æ•°

            params = self.get_step_params(step_name)
            
            # 3. è®¡ç®— max_proj (è¿™ä¸ª 'max_proj' ä¸ 'max_proj_seeds' ä¸åŒï¼Œ
            #    å®ƒæ˜¯åœ¨ mc è§†é¢‘ä¸Šè®¡ç®—çš„ï¼Œç”¨äº merge)
            self.log_output.append("-> æ­£åœ¨è®¡ç®— Max Projection (ç”¨äºåˆå¹¶)...")
            max_proj = varr_mc.max('frame').compute()
            # (æ³¨æ„: 'max_proj_seeds' ä»ç”¨äºå¯è§†åŒ–èƒŒæ™¯)
            
            # 4. åˆå¹¶ç§å­ç‚¹
            self.log_output.append(f"-> æ­£åœ¨å¯¹ {len(seeds_to_merge)} ä¸ªç§å­è¿›è¡Œåˆå¹¶...")
            
            # seeds_merge è¿”å›ä¸€ä¸ª DataFrameï¼Œå…¶ä¸­æ·»åŠ äº† 'mask_mrg' åˆ—
            seeds_with_mask = seeds_merge(varr_mc, max_proj, seeds_to_merge, **params)
            
            # ğŸ”´ ä¿®æ­£ 4: æ ¹æ® 'mask_mrg' åˆ†ç¦»ç§å­
            if 'mask_mrg' not in seeds_with_mask.columns:
                self.log_output.append(f"âŒ é”™è¯¯: 'seeds_merge' æœªè¿”å› 'mask_mrg' åˆ—ã€‚")
                raise ValueError("seeds_merge çš„è¾“å‡ºç¼ºå°‘ 'mask_mrg' åˆ—")

            # 'mask_mrg' ä¸º True è¡¨ç¤º*ä¿ç•™*
            seeds_kept = seeds_with_mask[seeds_with_mask['mask_mrg'] == True]
            seeds_removed = seeds_with_mask[seeds_with_mask['mask_mrg'] == False]

            # 5. ä¿å­˜ä¸¤ç»„åˆ†ç¦»çš„ç§å­
            self._save_data_to_repo(seeds_kept, output_key_kept)
            self._save_data_to_repo(seeds_removed, output_key_removed)

            self.log_output.append(f"âœ… ç§å­ç‚¹åˆå¹¶å®Œæˆã€‚")
            self.log_output.append(f"-> {len(seeds_kept)} ä¸ªç§å­è¢«ä¿ç•™ (ç™½è‰²)ã€‚")
            self.log_output.append(f"-> {len(seeds_removed)} ä¸ªç§å­è¢«ç§»é™¤ (çº¢è‰²)ã€‚")
            print(f"âœ… ç§å­ç‚¹åˆå¹¶å®Œæˆã€‚ä¿ç•™: {len(seeds_kept)}, ç§»é™¤: {len(seeds_removed)}")

            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(traceback.format_exc())
            self.update_step_status(step_name, "é”™è¯¯")
            return False


    def run_visualization_init(self) -> bool:
        """
        æ­¥éª¤ 9: åˆå§‹åŒ– (A, C, b, f)
        (å·²ä¿®æ­£ä¸ºä½¿ç”¨åˆ†æ‰¹å¤„ç†æ¥é¿å… ArrayMemoryError)
        """
        step_name = 'visualization_init'
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:            
            # 0. åŠ è½½æ•°æ®
            varr_mc_tuple = self._load_data_from_repo('varr_mc')
            if isinstance(varr_mc_tuple, tuple) and len(varr_mc_tuple) == 2:
                varr_mc = varr_mc_tuple[1]
            else:
                varr_mc = varr_mc_tuple
            
            seeds_to_init = self._load_data_from_repo('seeds_merged_kept')
            if seeds_to_init is None:
                raise ValueError("æœªæ‰¾åˆ° 'seeds_merged_kept' æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ 'merge_seeds' æ­¥éª¤ã€‚")
            if not isinstance(seeds_to_init, pd.DataFrame):
                 seeds_to_init = self._convert_seeds_to_df(seeds_to_init)
            
            if varr_mc is None:
                 raise ValueError("æ— æ³•åŠ è½½ 'varr_mc' æ•°æ®ã€‚")
            
            # 1. (å…³é”®) é‡åˆ†å—å¹¶ç”¨ 0 å¡«å……
            self.log_output.append("-> æ­£åœ¨é‡åˆ†å— (Rechunking) 'frame' ç»´åº¦...")
            varr_mc = varr_mc.chunk({'frame': -1})
            self.log_output.append("-> æ­£åœ¨ç”¨ 0 å¡«å…… (Fills NaNs with 0)...")
            varr_mc = varr_mc.fillna(0).astype(np.float32).persist()

            params = self.get_step_params(step_name)
            intpath = os.environ.get("MINIAN_INTERMEDIATE", "./intermediate_data")

            # 2. ğŸ”´ å†…å­˜é”™è¯¯ä¿®å¤ï¼šåˆ†æ‰¹å¤„ç† ğŸ”´
            
            batch_size = 500  # ä¸€æ¬¡å¤„ç† 500 ä¸ªç§å­
            n_seeds = len(seeds_to_init)
            A_init_list = [] # å­˜å‚¨æ¯ä¸ªæ‰¹æ¬¡çš„ A_init

            self.log_output.append(f"-> æ­£åœ¨å¯¹ {n_seeds} ä¸ªç§å­åˆ†æ‰¹ (æ¯æ‰¹ {batch_size} ä¸ª) åˆå§‹åŒ–ç©ºé—´è¶³è¿¹ A...")

            for i in range(0, n_seeds, batch_size):
                batch_start = i
                batch_end = min(i + batch_size, n_seeds)
                self.log_output.append(f"--> æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_start} to {batch_end}...")
                
                seeds_batch_df = seeds_to_init.iloc[batch_start:batch_end]
                
                # (A) ç©ºé—´åˆå§‹åŒ– A (é’ˆå¯¹æ‰¹æ¬¡)
                A_batch = initA(varr_mc, seeds_batch_df, **params.get('initA_kwargs', {}))
                
                # (B) å¼ºåˆ¶è®¡ç®—è¿™ä¸ªå°æ‰¹æ¬¡
                # è¿™å°†åªåŠ è½½è®¡ç®—è¿™ 500 ä¸ªç§å­æ‰€éœ€çš„æ•°æ®
                # åº”è¯¥å¯ä»¥é¿å… 551 MiB / 826 MiB çš„é”™è¯¯
                A_batch_computed = A_batch.persist() 
                
                A_init_list.append(A_batch_computed)
                self.log_output.append(f"--> æ‰¹æ¬¡ {batch_start} å®Œæˆ.")

            # (C) åˆå¹¶æ‰€æœ‰å·²è®¡ç®—çš„æ‰¹æ¬¡
            self.log_output.append("-> æ‰€æœ‰æ‰¹æ¬¡ A åˆå§‹åŒ–å®Œæˆï¼Œæ­£åœ¨åˆå¹¶...")
            A_init = xr.concat(A_init_list, dim="unit_id")
            
            # 3. æ—¶é—´åˆå§‹åŒ– C (ä¾èµ–äº A_init)
            self.log_output.append("-> æ­£åœ¨åˆå§‹åŒ–æ—¶é—´åºåˆ— C...")
            A_init = A_init.persist() # ç¡®ä¿åˆå¹¶åçš„ A åœ¨å†…å­˜ä¸­
            C_init = initC(varr_mc, A_init) 
            
            # 4. A å’Œ C çš„åˆå§‹åˆå¹¶
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œ A å’Œ C çš„åˆå§‹åˆå¹¶...")
            A_mrg, C_mrg = unit_merge(A_init, C_init, **params.get('init_merge_kwargs', {}))
            
            # 5. è®¡ç®—åˆå§‹èƒŒæ™¯ b å’Œ f
            self.log_output.append("-> æ­£åœ¨è®¡ç®—åˆå§‹èƒŒæ™¯ b å’Œ f...")
            A_mrg = A_mrg.persist()
            C_mrg = C_mrg.persist()
            b_init, f_init = update_background(varr_mc, A_mrg, C_mrg)

            # 6. ä¿å­˜æœ€ç»ˆçš„ A, C, b, f
            self.log_output.append("-> æ­£åœ¨ä¿å­˜ A, C, b, f...")
            
            A = save_minian(A_mrg.rename("A_init"), dpath=intpath, overwrite=True)
            C = save_minian(
                C_mrg.rename("C_init"), 
                dpath=intpath, 
                overwrite=True, 
                chunks=params.get('C_chunks', {"unit_id": 1, "frame": -1})
            )
            b = save_minian(b_init.rename("b_init"), dpath=intpath, overwrite=True)
            f = save_minian(f_init.rename("f_init"), dpath=intpath, overwrite=True)

            self._save_data_to_repo(A, "A_init")
            self._save_data_to_repo(C, "C_init")
            self._save_data_to_repo(b, "b_init")
            self._save_data_to_repo(f, "f_init")
            
            self.log_output.append("âœ… A, C, b, f åˆå§‹åŒ–å®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.log_output.append(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(f"--- è¯¦ç»†è¿½è¸ªæ ˆ ---\n{traceback.format_exc()}")
            print(traceback.format_exc())
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_first_spatial_update(self) -> bool:
        """
        æ­¥éª¤ 11: ç¬¬ä¸€æ¬¡ç©ºé—´æ›´æ–° (Update Spatial) ä¸èƒŒæ™¯æ›´æ–° (Update Background)
        å¹¶ä¿å­˜ A, C, b, f çš„æ–°å€¼ã€‚
        """
        step_name = 'first_spatial_update'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # import matplotlib.pyplot as plt # ä¸éœ€è¦ç›´æ¥å¯¼å…¥ï¼Œå› ä¸ºåœ¨ create_spatial_update_plot å†…éƒ¨å¤„ç†

            # 1. åŠ è½½æ•°æ®
            intpath = os.environ.get("MINIAN_INTERMEDIATE", "./intermediate_data")
            varr_mc = self._load_data_from_repo('varr_mc')
            A_init = self._load_data_from_repo('A_init')
            C_init = self._load_data_from_repo('C_init')
            C_chk_init = self._load_data_from_repo('C_init').rename("C_chk") 
            sn_spatial = self._load_data_from_repo('sn_spatial') 
            chk = self._load_data_from_repo('chk_settings')
            
            params = self.get_step_params(step_name)
            spatial_kwargs = params.get('spatial_kwargs', {})

            # --- ç¬¬ä¸€æ¬¡ç©ºé—´æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œç¬¬ä¸€æ¬¡ç©ºé—´æ›´æ–°...")
            A_new, mask, norm_fac = update_spatial(
                varr_mc, A_init, C_init, sn_spatial, **spatial_kwargs
            )

            C_new = (C_init.sel(unit_id=mask) * norm_fac).rename("C_new")
            C_new = save_minian(C_new, intpath, overwrite=True)
            self._save_data_to_repo(C_new, "C_new_iter1")

            C_chk_new = (C_chk_init.sel(unit_id=mask) * norm_fac).rename("C_chk_new")
            C_chk_new = save_minian(C_chk_new, intpath, overwrite=True)
            self._save_data_to_repo(C_chk_new, "C_chk_new_iter1")

            # --- èƒŒæ™¯æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡ŒèƒŒæ™¯æ›´æ–°...")
            b_new, f_new = update_background(varr_mc, A_new, C_chk_new)
            
            # --- å¯è§†åŒ– (2x2 ç©ºé—´è¶³è¿¹å¯¹æ¯”) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆç©ºé—´æ›´æ–°å¯è§†åŒ–ç»“æœ (Matplotlib 2x2)ã€‚")
            
            # 1. å‡†å¤‡æ•°æ® (è®¡ç®— Dask æ•°ç»„å¹¶è½¬æ¢ä¸º NumPy)
            A_init_max = A_init.max("unit_id").compute().astype(np.float32).values
            A_init_sum = (A_init.fillna(0) > 0).sum("unit_id").compute().astype(np.uint8).values
            A_new_max = A_new.max("unit_id").compute().astype(np.float32).values
            A_new_sum = (A_new > 0).sum("unit_id").compute().astype(np.uint8).values
            
            # 2. è°ƒç”¨æ–°çš„å¯è§†åŒ–å‡½æ•°
            img_array = create_spatial_update_plot(
                A_init_max, 
                A_init_sum, 
                A_new_max, 
                A_new_sum, 
                step_name="First Update" # ä¼ å…¥ step_name åŒºåˆ†
            )

            # 3. ä¿å­˜ NumPy æ•°ç»„ä¾› PyQt æ˜¾ç¤º
            self._save_data_to_repo(img_array, f"{step_name}_vis_array")
            
            # --- ä¿å­˜æœ€ç»ˆç»“æœå¹¶æ›´æ–° repo ä¸­çš„ä¸»é”® ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜ A, C, b, f çš„ç¬¬ä¸€æ¬¡è¿­ä»£ç»“æœ...")

            A = save_minian(
                A_new.rename("A"),
                intpath,
                overwrite=True,
                chunks=params.get('A_chunks', {"unit_id": 1, "height": -1, "width": -1}),
            )
            self._save_data_to_repo(A, "A_iter1")
            
            b = save_minian(b_new.rename("b"), intpath, overwrite=True)
            self._save_data_to_repo(b, "b_iter1")

            f = save_minian(
                f_new.chunk({"frame": chk["frame"]}).rename("f"), intpath, overwrite=True
            )
            self._save_data_to_repo(f, "f_iter1")

            C = save_minian(C_new.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C, "C_iter1")

            C_chk = save_minian(C_chk_new.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk, "C_chk_iter1")

            self.log_output.append("âœ… æ­¥éª¤ 11 è¿è¡Œå®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    # è¯·æ³¨æ„ï¼š run_first_temporal_update_explore (æ­¥éª¤ 12) ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒä½¿ç”¨ Holoviews/Bokeh é£æ ¼çš„ visualize_temporal_update
    # å‡è®¾ create_cnmf_update_plot, compute_trace, update_temporal ç­‰å·²å¯¼å…¥

    def run_first_temporal_update_explore(self) -> bool:
        """
        æ­¥éª¤ 12: åˆæ¬¡æ—¶é—´æ›´æ–° (å‚æ•°æ¢ç´¢) - ä¿®æ”¹ä¸º Matplotlib å•ä¸ªå•å…ƒå››å®«æ ¼å›¾
        """
        step_name = 'first_temporal_update_explore'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # 1. åŠ è½½æ•°æ®
            varr_mc = self._load_data_from_repo('varr_mc') # å¯¹åº” Y_fm_chk
            A_init = self._load_data_from_repo('A_init') # å¯¹åº” A
            C_init = self._load_data_from_repo('C_init') # å¯¹åº” C_chk
            
            b_current = self._load_data_from_repo('b_iter1', allow_none=True)
            f_current = self._load_data_from_repo('f_iter1', allow_none=True)
            # ... (b_current/f_current åˆå§‹åŒ–ä»£ç ä¸å˜) ...
            if b_current is None:
                b_current = xr.zeros_like(varr_mc.isel(frame=0, drop=True)).rename("b")
            if f_current is None:
                f_current = xr.zeros_like(varr_mc.isel(height=0, width=0).mean(dim=["height", "width"], drop=True)).rename("f")

            # 2. è·å–å•ä¸ªå‚æ•°ç»„åˆ
            params = self.get_step_params(step_name)
            p = params.get('p', 1)
            sparse_penal = params.get('sparse_penal', 1.0)
            add_lag = params.get('add_lag', 20)
            noise_freq = params.get('noise_freq', 0.06)

            # 3. é€‰å–å­é›†å•ä½ (Units)
            self.log_output.append("-> æ­£åœ¨é€‰å– 10 ä¸ªéšæœºå•ä½è¿›è¡Œæ—¶é—´æ›´æ–°æ¢ç´¢ã€‚")
            all_units = A_init.coords["unit_id"].values
            units_to_select = min(10, len(all_units))
            np.random.seed(1) 
            units = np.random.choice(all_units, units_to_select, replace=False)
            units.sort()
            
            A_sub = A_init.sel(unit_id=units).persist()
            C_sub = C_init.sel(unit_id=units).persist()
            
            # 4. è®¡ç®—æ®‹å·® (YrA)
            self.log_output.append("-> æ­£åœ¨è®¡ç®— YrA (æ®‹å·®/trace)...")
            # å‡è®¾ compute_trace è¿”å› Y_rA (å³ Y - b*f) å‡å»å•ä½æœ¬èº«è´¡çŒ®åçš„ä¿¡å·
            # Minian çš„ compute_trace å®é™…ä¸Šæ˜¯ (Y - b*f) * A.T
            # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å‡è®¾å®ƒè¿”å›äº†æ­£ç¡®çš„è¾“å…¥ä¿¡å· (Y_rA)
            YrA = compute_trace(
                varr_mc, A_sub, b_current, C_sub, f_current
            ).persist().chunk({"unit_id": 1, "frame": -1})
            
            self.log_output.append(f"-> æ‰§è¡Œæ¢ç´¢ (p={p}, sparse_penal={sparse_penal}, add_lag={add_lag}, noise_freq={noise_freq})...")

            # 5. è¿è¡Œ update_temporal (å•å‚æ•°)
            cur_C, cur_S, cur_b0, cur_c0, cur_g, cur_mask = update_temporal(
                A_sub,
                C_sub,
                YrA=YrA,
                sparse_penal=sparse_penal,
                p=p,
                use_smooth=True,
                add_lag=add_lag,
                noise_freq=noise_freq,
            )
            
            # 6. å¯è§†åŒ–ï¼šä½¿ç”¨ create_cnmf_update_plot (æ›¿ä»£æ–¹æ¡ˆ)
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆæ—¶é—´æ›´æ–°å¯è§†åŒ–ç»“æœ (Matplotlib/ä»£è¡¨æ€§å•å…ƒ)ã€‚")
            
            # é€‰å–ä¸€ä¸ªä»£è¡¨æ€§ Unit ID (ä¾‹å¦‚ç¬¬ä¸€ä¸ª)
            representative_unit_id = units[0]
            # é€‰å–ä¸€ä¸ªä»£è¡¨æ€§å¸§
            frame_idx = 0 
            
            # ä¸ºäº† create_cnmf_update_plotï¼Œæˆ‘ä»¬éœ€è¦ A, C, S çš„ Xarray DataArray
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥æ˜¾ç¤º C ä¸ YrA çš„å¯¹æ¯”ï¼Œåªèƒ½æ˜¾ç¤º C æœ¬èº« (å³å››å®«æ ¼å›¾çš„ C å›¾)
            img_array = create_cnmf_update_plot(
                varr=self.Y_ds, # å‡è®¾ self.Y_ds æ˜¯åŸå§‹è§†é¢‘ï¼Œç”¨äºèƒŒæ™¯
                A_comp=A_sub.compute(), 
                C_comp=cur_C.compute(), 
                S_comp=cur_S.compute(), 
                unit_id=representative_unit_id, 
                frame_idx=frame_idx
            )
            
            # 7. ä¿å­˜å›¾åƒ
            image_path = f"{step_name}_temporal_cnmf_plot.png"
            full_path = os.path.join(self.repo_dir, image_path)
            cv2.imwrite(full_path, cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)) 
            self._save_data_to_repo(image_path, f"{step_name}_vis")
            
            self.log_output.append("âœ… æ­¥éª¤ 12 è¿è¡Œå®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_first_temporal_update(self) -> bool:
        """
        æ­¥éª¤ 13: ç¬¬ä¸€æ¬¡æ—¶é—´æ›´æ–° (Update Temporal) å’Œå•ä½åˆå¹¶ (Unit Merge)
        æ›´æ–° A, C, S, b0, c0 çš„æ–°å€¼ã€‚
        """
        step_name = 'first_temporal_update'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # 1. åŠ è½½æ•°æ® (ä½¿ç”¨è¿­ä»£ 1 çš„ç»“æœ)
            intpath = os.environ.get("MINIAN_INTERMEDIATE", "./intermediate_data")
            varr_mc = self._load_data_from_repo('varr_mc')
            A_current = self._load_data_from_repo('A_iter1')
            C_current = self._load_data_from_repo('C_iter1')
            C_chk_current = self._load_data_from_repo('C_chk_iter1')
            b_current = self._load_data_from_repo('b_iter1')
            f_current = self._load_data_from_repo('f_iter1')
            chk = self._load_data_from_repo('chk_settings') 
            
            params = self.get_step_params(step_name)
            temporal_kwargs = params.get('temporal_kwargs', {})
            merge_kwargs = params.get('merge_kwargs', {}) # ç¡®ä¿è·å– merge_kwargs

            # --- è®¡ç®— YrA ---
            self.log_output.append("-> æ­£åœ¨è®¡ç®— YrA (æ®‹å·®/trace)...")
            YrA = compute_trace(
                varr_mc, A_current, b_current, C_chk_current, f_current
            ).persist() 

            # --- ç¬¬ä¸€æ¬¡æ—¶é—´æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œç¬¬ä¸€æ¬¡æ—¶é—´æ›´æ–°...")
            C_new, S_new, b0_new, c0_new, g, mask = update_temporal(
                A_current, C_current, YrA=YrA, **temporal_kwargs
            )
            
            C_new = C_new.rename("C_new")
            C_chk_new = C_chk_current.sel(unit_id=C_new.coords["unit_id"].values).rename("C_chk_new") # è°ƒæ•´ C_chk_new çš„å¤§å°

            # --- å¯è§†åŒ– (åˆå§‹/ç¬¬ä¸€æ¬¡æ›´æ–° C/S çŸ©é˜µå›¾) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆæ—¶é—´æ›´æ–°å’Œäº‹ä»¶çš„çŸ©é˜µå¯è§†åŒ–ç»“æœã€‚")
            
            C_init_comp = C_current.compute().astype(np.float32).values
            C_new_comp = C_new.compute().astype(np.float32).values
            S_new_comp = S_new.compute().astype(np.float32).values
            
            # è°ƒç”¨æ–°çš„ C/S çŸ©é˜µå¯è§†åŒ–å‡½æ•°
            img_array_c_s = create_temporal_matrix_plot(
                C_init_comp, 
                C_new_comp, 
                S_new_comp, 
                step_name="First Update"
            )
            self._save_data_to_repo(img_array_c_s, f"{step_name}_c_s_vis_array")
            
            # --- å¯è§†åŒ– (æ¥å—å•ä½çš„ç»†èŠ‚) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆæ¥å—å•ä½çš„è¯¦ç»†æ—¶é—´æ›´æ–°å¯è§†åŒ– (10ä¸ªæ ·æœ¬)ã€‚")
            sig = C_new + b0_new + c0_new
            
            accepted_units = C_new.coords["unit_id"].values
            units_to_sample = min(10, len(accepted_units))
            np.random.seed(2) 
            sample_units = np.random.choice(accepted_units, units_to_sample, replace=False)
            
            A_comp = A_current.sel(unit_id=sample_units).compute()
            C_comp = C_new.sel(unit_id=sample_units).compute()
            S_comp = S_new.sel(unit_id=sample_units).compute()
            
            # æ‰¾åˆ°å¹³å‡Cæœ€å¤§çš„å¸§ä½œä¸ºé‡å»ºå¸§
            mean_C_idx = int(C_comp.mean('unit_id').argmax().values)
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬å•ä½åˆ›å»ºå¹¶ä¿å­˜è¯¦ç»†å››å®«æ ¼å›¾
            for i, unit_id in enumerate(sample_units):
                img_array_unit = create_cnmf_update_plot(
                    varr_mc, 
                    A_comp, 
                    C_comp, 
                    S_comp, 
                    unit_id, 
                    mean_C_idx
                )
                self._save_data_to_repo(img_array_unit, f"{step_name}_accepted_unit_{unit_id}_vis_array")


            # --- ä¸´æ—¶ä¿å­˜ C, C_chk, S, b0, c0 ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜æ—¶é—´æ›´æ–°ç»“æœ...")
            
            C_current = save_minian(C_new.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C_current, "C_tmp_merge")

            C_chk_current = save_minian(C_chk_new.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk_current, "C_chk_tmp_merge")

            S_current = save_minian(S_new.rename("S"), intpath, overwrite=True)
            self._save_data_to_repo(S_current, "S_tmp_merge")

            b0_current = save_minian(b0_new.rename("b0"), intpath, overwrite=True)
            self._save_data_to_repo(b0_current, "b0_tmp_merge")
            
            c0_current = save_minian(c0_new.rename("c0"), intpath, overwrite=True)
            self._save_data_to_repo(c0_current, "c0_tmp_merge")
            
            A_current = A_current.sel(unit_id=C_current.coords["unit_id"].values)
            self._save_data_to_repo(A_current, "A_tmp_merge")

            # --- å•ä½åˆå¹¶ ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œå•ä½åˆå¹¶...")
            A_mrg, C_mrg, sig_mrg_list = unit_merge(
                A_current, 
                C_current, 
                [C_current + b0_current + c0_current], 
                **merge_kwargs
            )
            sig_mrg = sig_mrg_list[0] 

            # --- åˆå¹¶å¯è§†åŒ– (C çŸ©é˜µå›¾å¯¹æ¯”) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆåˆå¹¶å¯¹æ¯”å¯è§†åŒ–ã€‚")
            
            C_before_comp = C_current.compute().astype(np.float32).values
            C_after_comp = C_mrg.compute().astype(np.float32).values
            
            # è°ƒç”¨æ–°çš„åˆå¹¶çŸ©é˜µå¯è§†åŒ–å‡½æ•°
            img_array_merge = create_merge_matrix_plot(
                C_before_comp, 
                C_after_comp, 
                step_name="First Merge"
            )
            self._save_data_to_repo(img_array_merge, f"{step_name}_merge_vis_array")

            # --- ä¿å­˜æœ€ç»ˆåˆå¹¶ç»“æœå¹¶æ›´æ–° repo ä¸­çš„ä¸»é”® ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜æœ€ç»ˆåˆå¹¶ç»“æœ...")

            A_current = save_minian(A_mrg.rename("A"), intpath, overwrite=True)
            self._save_data_to_repo(A_current, "A_iter1_merged")

            C_current = save_minian(C_mrg.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C_current, "C_iter1_merged")

            C_chk_current = save_minian(C_current.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk_current, "C_chk_iter1_merged")

            sig_current = save_minian(sig_mrg.rename("sig"), intpath, overwrite=True)
            self._save_data_to_repo(sig_current, "sig_iter1_merged")

            self.log_output.append("âœ… æ­¥éª¤ 13 è¿è¡Œå®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False
    
    def run_second_spatial_update(self) -> bool:
        """
        æ­¥éª¤ 14: ç¬¬äºŒæ¬¡ç©ºé—´æ›´æ–° (Update Spatial) ä¸èƒŒæ™¯æ›´æ–° (Update Background)
        å¹¶ä¿å­˜ A, C, b, f çš„ç¬¬äºŒæ¬¡è¿­ä»£ç»“æœã€‚
        """
        step_name = 'second_spatial_update'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # 1. åŠ è½½æ•°æ® (ä½¿ç”¨ç¬¬ä¸€æ¬¡åˆå¹¶åçš„ç»“æœä½œä¸ºèµ·ç‚¹)
            intpath = os.environ.get("MINIAN_INTERMEDIATE", "./intermediate_data")
            varr_mc = self._load_data_from_repo('varr_mc')
            A_init = self._load_data_from_repo('A_iter1_merged') # A è¿­ä»£èµ·ç‚¹
            C_init = self._load_data_from_repo('C_iter1_merged') # C è¿­ä»£èµ·ç‚¹
            C_chk_init = self._load_data_from_repo('C_chk_iter1_merged').rename("C_chk") 
            sn_spatial = self._load_data_from_repo('sn_spatial') 
            chk = self._load_data_from_repo('chk_settings')
            
            params = self.get_step_params(step_name)
            # å‡è®¾ç¬¬äºŒæ¬¡è¿­ä»£çš„å‚æ•°é”®ä¸º 'spatial_kwargs_iter2'
            spatial_kwargs = params.get('spatial_kwargs_iter2', {}) 

            # --- ç¬¬äºŒæ¬¡ç©ºé—´æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œç¬¬äºŒæ¬¡ç©ºé—´æ›´æ–°...")
            # ä½¿ç”¨ç¬¬äºŒæ¬¡å‚æ•°è¿›è¡Œ update_spatial
            A_new, mask, norm_fac = update_spatial(
                varr_mc, A_init, C_init, sn_spatial, **spatial_kwargs
            )

            C_new = (C_init.sel(unit_id=mask) * norm_fac).rename("C_new")
            C_new = save_minian(C_new, intpath, overwrite=True)
            self._save_data_to_repo(C_new, "C_new_iter2")

            C_chk_new = (C_chk_init.sel(unit_id=mask) * norm_fac).rename("C_chk_new")
            C_chk_new = save_minian(C_chk_new, intpath, overwrite=True)
            self._save_data_to_repo(C_chk_new, "C_chk_new_iter2")

            # --- èƒŒæ™¯æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡ŒèƒŒæ™¯æ›´æ–°...")
            b_new, f_new = update_background(varr_mc, A_new, C_chk_new)
            
            # --- å¯è§†åŒ– (2x2 ç©ºé—´è¶³è¿¹å¯¹æ¯”) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆç¬¬äºŒæ¬¡ç©ºé—´æ›´æ–°å¯è§†åŒ–ç»“æœ (Matplotlib 2x2)ã€‚")
            
            # 1. å‡†å¤‡æ•°æ® (è®¡ç®— Dask æ•°ç»„å¹¶è½¬æ¢ä¸º NumPy)
            A_init_max = A_init.max("unit_id").compute().astype(np.float32).values
            A_init_sum = (A_init.fillna(0) > 0).sum("unit_id").compute().astype(np.uint8).values
            A_new_max = A_new.max("unit_id").compute().astype(np.float32).values
            A_new_sum = (A_new > 0).sum("unit_id").compute().astype(np.uint8).values
            
            # 2. è°ƒç”¨æ–°çš„å¯è§†åŒ–å‡½æ•°
            img_array = create_spatial_update_plot(
                A_init_max, 
                A_init_sum, 
                A_new_max, 
                A_new_sum, 
                step_name="Second Update" # ä¼ å…¥ step_name åŒºåˆ†
            )

            # 3. ä¿å­˜ NumPy æ•°ç»„ä¾› PyQt æ˜¾ç¤º
            self._save_data_to_repo(img_array, f"{step_name}_vis_array")

            # --- ä¿å­˜æœ€ç»ˆç»“æœå¹¶æ›´æ–° repo ä¸­çš„ä¸»é”® (Iter 2 çš„åˆå§‹æ•°æ®) ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜ A, C, b, f çš„ç¬¬äºŒæ¬¡è¿­ä»£ç»“æœ...")

            A = save_minian(
                A_new.rename("A"),
                intpath,
                overwrite=True,
                chunks=params.get('A_chunks', {"unit_id": 1, "height": -1, "width": -1}),
            )
            self._save_data_to_repo(A, "A_iter2")
            
            b = save_minian(b_new.rename("b"), intpath, overwrite=True)
            self._save_data_to_repo(b, "b_iter2")

            f = save_minian(
                f_new.chunk({"frame": chk["frame"]}).rename("f"), intpath, overwrite=True
            )
            self._save_data_to_repo(f, "f_iter2")

            C = save_minian(C_new.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C, "C_iter2")

            C_chk = save_minian(C_chk_new.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk, "C_chk_iter2")

            self.log_output.append("âœ… æ­¥éª¤ 14 è¿è¡Œå®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_second_temporal_update(self) -> bool:
        """
        æ­¥éª¤ 15: ç¬¬äºŒæ¬¡æ—¶é—´æ›´æ–° (Update Temporal) å’Œå•ä½åˆå¹¶ (Unit Merge)
        æ›´æ–° A, C, S, b0, c0 çš„æ–°å€¼ã€‚
        """
        step_name = 'second_temporal_update'
        self.update_step_status(step_name, "è¿è¡Œä¸­")
        try:
            # 1. åŠ è½½æ•°æ® (ä½¿ç”¨è¿­ä»£ 2 ç©ºé—´æ›´æ–°åçš„ç»“æœ)
            intpath = os.environ.get("MINIAN_INTERMEDIATE", "./intermediate_data")
            varr_mc = self._load_data_from_repo('varr_mc')
            A_current = self._load_data_from_repo('A_iter2') # å¯¹åº” A
            C_current = self._load_data_from_repo('C_iter2') # å¯¹åº” C
            C_chk_current = self._load_data_from_repo('C_chk_iter2') # å¯¹åº” C_chk
            b_current = self._load_data_from_repo('b_iter2') # å¯¹åº” b
            f_current = self._load_data_from_repo('f_iter2') # å¯¹åº” f
            chk = self._load_data_from_repo('chk_settings') 
            
            params = self.get_step_params(step_name)
            # å‡è®¾ç¬¬äºŒæ¬¡è¿­ä»£çš„å‚æ•°é”®
            temporal_kwargs = params.get('temporal_kwargs_iter2', {})
            merge_kwargs = params.get('merge_kwargs_iter2', {})

            # --- è®¡ç®— YrA ---
            self.log_output.append("-> æ­£åœ¨è®¡ç®— YrA (æ®‹å·®/trace)...")
            YrA = compute_trace(
                varr_mc, A_current, b_current, C_chk_current, f_current
            ).persist() 

            # --- ç¬¬äºŒæ¬¡æ—¶é—´æ›´æ–° ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œç¬¬äºŒæ¬¡æ—¶é—´æ›´æ–°...")
            # ä½¿ç”¨ç¬¬äºŒæ¬¡å‚æ•°è¿›è¡Œ update_temporal
            C_new, S_new, b0_new, c0_new, g, mask = update_temporal(
                A_current, C_current, YrA=YrA, **temporal_kwargs
            )
            
            C_new = C_new.rename("C_new")
            C_chk_new = C_chk_current.sel(unit_id=C_new.coords["unit_id"].values).rename("C_chk_new")

            # --- å¯è§†åŒ– (åˆå§‹/ç¬¬äºŒæ¬¡æ›´æ–° C/S çŸ©é˜µå›¾) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆæ—¶é—´æ›´æ–°å’Œäº‹ä»¶çš„çŸ©é˜µå¯è§†åŒ–ç»“æœã€‚")
            
            C_init_comp = C_current.compute().astype(np.float32).values
            C_new_comp = C_new.compute().astype(np.float32).values
            S_new_comp = S_new.compute().astype(np.float32).values
            
            # è°ƒç”¨æ–°çš„ C/S çŸ©é˜µå¯è§†åŒ–å‡½æ•°
            img_array_c_s = create_temporal_matrix_plot(
                C_init_comp, 
                C_new_comp, 
                S_new_comp, 
                step_name="Second Update"
            )
            self._save_data_to_repo(img_array_c_s, f"{step_name}_c_s_vis_array")
            
            # --- å¯è§†åŒ– (æ¥å—å•ä½çš„ç»†èŠ‚) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆæ¥å—å•ä½çš„è¯¦ç»†æ—¶é—´æ›´æ–°å¯è§†åŒ– (10ä¸ªæ ·æœ¬)ã€‚")
            sig = C_new + b0_new + c0_new
            
            accepted_units = C_new.coords["unit_id"].values
            units_to_sample = min(10, len(accepted_units))
            np.random.seed(3) # æ–°çš„éšæœºç§å­
            sample_units = np.random.choice(accepted_units, units_to_sample, replace=False)
            
            A_comp = A_current.sel(unit_id=sample_units).compute()
            C_comp = C_new.sel(unit_id=sample_units).compute()
            S_comp = S_new.sel(unit_id=sample_units).compute()
            
            mean_C_idx = int(C_comp.mean('unit_id').argmax().values)
            
            for i, unit_id in enumerate(sample_units):
                img_array_unit = create_cnmf_update_plot(
                    varr_mc, 
                    A_comp, 
                    C_comp, 
                    S_comp, 
                    unit_id, 
                    mean_C_idx
                )
                self._save_data_to_repo(img_array_unit, f"{step_name}_accepted_unit_{unit_id}_vis_array")


            # --- ä¸´æ—¶ä¿å­˜ C, C_chk, S, b0, c0 ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜æ—¶é—´æ›´æ–°ç»“æœ...")
            
            C_current = save_minian(C_new.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C_current, "C_tmp_merge")

            C_chk_current = save_minian(C_chk_new.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk_current, "C_chk_tmp_merge")

            S_current = save_minian(S_new.rename("S"), intpath, overwrite=True)
            self._save_data_to_repo(S_current, "S_tmp_merge")

            b0_current = save_minian(b0_new.rename("b0"), intpath, overwrite=True)
            self._save_data_to_repo(b0_current, "b0_tmp_merge")
            
            c0_current = save_minian(c0_new.rename("c0"), intpath, overwrite=True)
            self._save_data_to_repo(c0_current, "c0_tmp_merge")
            
            A_current = A_current.sel(unit_id=C_current.coords["unit_id"].values)
            self._save_data_to_repo(A_current, "A_tmp_merge")

            # --- å•ä½åˆå¹¶ ---
            self.log_output.append("-> æ­£åœ¨æ‰§è¡Œå•ä½åˆå¹¶...")
            A_mrg, C_mrg, sig_mrg_list = unit_merge(
                A_current, 
                C_current, 
                [C_current + b0_current + c0_current], 
                **merge_kwargs
            )
            sig_mrg = sig_mrg_list[0] 

            # --- åˆå¹¶å¯è§†åŒ– (C çŸ©é˜µå›¾å¯¹æ¯”) ---
            self.log_output.append("-> æ­£åœ¨ç”Ÿæˆåˆå¹¶å¯¹æ¯”å¯è§†åŒ–ã€‚")
            
            C_before_comp = C_current.compute().astype(np.float32).values
            C_after_comp = C_mrg.compute().astype(np.float32).values
            
            # è°ƒç”¨æ–°çš„åˆå¹¶çŸ©é˜µå¯è§†åŒ–å‡½æ•°
            img_array_merge = create_merge_matrix_plot(
                C_before_comp, 
                C_after_comp, 
                step_name="Second Merge"
            )
            self._save_data_to_repo(img_array_merge, f"{step_name}_merge_vis_array")


            # --- ä¿å­˜æœ€ç»ˆåˆå¹¶ç»“æœå¹¶æ›´æ–° repo ä¸­çš„ä¸»é”® ---
            self.log_output.append("-> æ­£åœ¨ä¿å­˜æœ€ç»ˆåˆå¹¶ç»“æœ...")

            A_current = save_minian(A_mrg.rename("A"), intpath, overwrite=True)
            self._save_data_to_repo(A_current, "A_iter2_merged")

            C_current = save_minian(C_mrg.rename("C"), intpath, overwrite=True)
            self._save_data_to_repo(C_current, "C_iter2_merged")

            C_chk_current = save_minian(C_current.rename("C_chk"), intpath, overwrite=True)
            self._save_data_to_repo(C_chk_current, "C_chk_iter2_merged")

            sig_current = save_minian(sig_mrg.rename("sig"), intpath, overwrite=True)
            self._save_data_to_repo(sig_current, "sig_iter2_merged")

            self.log_output.append("âœ… æ­¥éª¤ 15 è¿è¡Œå®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True

        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False

    def run_save_data(self) -> bool:
        """
        æ­¥éª¤ 16: æ•°æ®ä¿å­˜
        å°†æœ€ç»ˆç»“æœä¿å­˜åˆ° Minian æ–‡ä»¶ä¸­ï¼ˆé€šå¸¸æ˜¯ minian.ncï¼‰ã€‚
        """
        step_name = 'save_data'
        self.update_step_status(step_name, "è¿è¡Œä¸­")

        try:
            # from .utilities import save_minian
            # æœ€ç»ˆæ•°æ®é€šå¸¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£çš„ç»“æœ
            A = self._load_data_from_repo("A_iter2")
            C = self._load_data_from_repo("C_iter2")
            S = self._load_data_from_repo("S_iter2")
            b = self._load_data_from_repo("b_iter2")
            f = self._load_data_from_repo("f_iter2")
            
            params = self.get_step_params(step_name)

            self.log_output.append("-> æ­£åœ¨ä¿å­˜æœ€ç»ˆ CNMF ç»“æœ (A, C, S, b, f)...")
            
            # ä½¿ç”¨ save_minian å‡½æ•°å°† Dask æ•°ç»„æŒä¹…åŒ–åˆ° Zarr å­˜å‚¨æˆ– .nc æ–‡ä»¶
            save_minian_kwargs = params.get('save_minian_kwargs', {'dpath': './minian_output', 'overwrite': True})
            
            A = save_minian(A.rename("A"), **save_minian_kwargs)
            C = save_minian(C.rename("C"), **save_minian_kwargs)
            S = save_minian(S.rename("S"), **save_minian_kwargs)
            b = save_minian(b.rename("b"), **save_minian_kwargs)
            f = save_minian(f.rename("f"), **save_minian_kwargs)
            
            self.log_output.append("âœ… æ‰€æœ‰æ•°æ®ä¿å­˜å®Œæˆã€‚")
            self.update_step_status(step_name, "å·²å®Œæˆ")
            return True
            
        except Exception as e:
            self.log_output.append(f"è¿è¡Œã€{step_name}ã€‘å¤±è´¥: {e}")
            self.update_step_status(step_name, "é”™è¯¯")
            return False